{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from math import log\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'C:\\Users\\kalya\\OneDrive - University of Illinois at Chicago\\!UIC\\!Semesters\\3rd Sem\\CS 583 Data Mining and Text Mining\\Assignements\\Assignment 2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['YOUNG', 'FALSE', 'FALSE', 'Fair', 'Semi-Yes'],\n",
       "       ['YOUNG', 'FALSE', 'FALSE', 'Good', 'No'],\n",
       "       ['YOUNG', 'TRUE', 'FALSE', 'Good', 'Semi-Yes'],\n",
       "       ['YOUNG', 'TRUE', 'TRUE', 'Fair', 'Semi-Yes'],\n",
       "       ['YOUNG', 'FALSE', 'FALSE', 'Fair', 'No'],\n",
       "       ['MIDDLE', 'FALSE', 'FALSE', 'Fair', 'No'],\n",
       "       ['MIDDLE', 'FALSE', 'FALSE', 'Good', 'Semi-Yes'],\n",
       "       ['MIDDLE', 'TRUE', 'TRUE', 'Good', 'Yes'],\n",
       "       ['MIDDLE', 'FALSE', 'TRUE', 'Excellent', 'Semi-Yes'],\n",
       "       ['MIDDLE', 'FALSE', 'TRUE', 'Excellent', 'Yes'],\n",
       "       ['OLD', 'FALSE', 'TRUE', 'Excellent', 'Semi-Yes'],\n",
       "       ['OLD', 'FALSE', 'TRUE', 'Good', 'Yes'],\n",
       "       ['OLD', 'TRUE', 'FALSE', 'Good', 'Yes'],\n",
       "       ['OLD', 'TRUE', 'FALSE', 'Excellent', 'Yes'],\n",
       "       ['OLD', 'FALSE', 'FALSE', 'Fair', 'No']], dtype='<U9')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = np.loadtxt(fname = os.path.join(file_path, 'ori_testdataset1.csv'), delimiter= '\\n', dtype= str)\n",
    "data_temp = [i.replace('{','').replace('}', '').split(',') for i in temp]\n",
    "data = np.asarray([[i for i in j] for j in data_temp])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['YOUNG', 'YOUNG', 'YOUNG', 'YOUNG', 'YOUNG', 'MIDDLE', 'MIDDLE',\n",
       "        'MIDDLE', 'MIDDLE', 'MIDDLE', 'OLD', 'OLD', 'OLD', 'OLD', 'OLD'],\n",
       "       ['FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE',\n",
       "        'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE',\n",
       "        'FALSE'],\n",
       "       ['FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE',\n",
       "        'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE',\n",
       "        'FALSE'],\n",
       "       ['Fair', 'Good', 'Good', 'Fair', 'Fair', 'Fair', 'Good', 'Good',\n",
       "        'Excellent', 'Excellent', 'Excellent', 'Good', 'Good',\n",
       "        'Excellent', 'Fair'],\n",
       "       ['Semi-Yes', 'No', 'Semi-Yes', 'Semi-Yes', 'No', 'No', 'Semi-Yes',\n",
       "        'Yes', 'Semi-Yes', 'Yes', 'Semi-Yes', 'Yes', 'Yes', 'Yes', 'No']],\n",
       "      dtype='<U9')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_transpose = np.transpose(data)\n",
    "data_transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['MIDDLE', 'OLD', 'YOUNG'], dtype='<U9'),\n",
       " array(['FALSE', 'TRUE'], dtype='<U9'),\n",
       " array(['FALSE', 'TRUE'], dtype='<U9'),\n",
       " array(['Excellent', 'Fair', 'Good'], dtype='<U9'),\n",
       " array(['No', 'Semi-Yes', 'Yes'], dtype='<U9')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniq_attr = [np.unique(i) for i in data_transpose]\n",
    "uniq_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Semi-Yes', 'Yes'], dtype='<U9')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniq_attr[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.565596230357602"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def entropy_root(data):\n",
    "    (unique, counts) = np.unique(data, return_counts=True)\n",
    "    n = len(data)\n",
    "    ent =0\n",
    "    for i in counts:\n",
    "        p = i/n\n",
    "        ent+= -(p*log(p,2))\n",
    "        \n",
    "    \n",
    "    return ent\n",
    "\n",
    "\n",
    "root_ent = entropy_root(data_transpose[-1])    \n",
    "root_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.174"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def entropy(attr, clas):\n",
    "    ent = 0\n",
    "    uniq = np.unique(attr)\n",
    "    uniq_class = np.unique(clas)\n",
    "#     print(uniq_class)\n",
    "    for i in uniq:\n",
    "        temp_ent = 0\n",
    "        temp = np.zeros(len(uniq_class))\n",
    "#         print(temp)\n",
    "        indices = np.where(attr == i)\n",
    "#         print(indices[0])\n",
    "        n = len(indices[0])\n",
    "#         print(n/len(data))\n",
    "#         print(z)\n",
    "        for j in indices[0]:\n",
    "#             print(j)\n",
    "            for k in range(len(uniq_class)):\n",
    "                if clas[j] == uniq_class[k]:\n",
    "                    temp[k] += 1\n",
    "        temp_p = temp/n\n",
    "#         print(temp_p)\n",
    "#         print(z)\n",
    "        for i in temp_p:\n",
    "            if i != 0:\n",
    "                temp_ent += -(i*log(i,2))\n",
    "#         print(temp_ent)  \n",
    "#         print(z)\n",
    "        ent += temp_ent*(n/len(data))\n",
    "#     print(ent)\n",
    "#     print(z)\n",
    "\n",
    "        \n",
    "    return round(ent,3)\n",
    "    \n",
    "        \n",
    "entropy(data_transpose[3], data_transpose[-1])\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ig(data, attr):\n",
    "    return round(entropy_root(data_transpose[-1]) - entropy(attr, data_transpose[-1]),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.278, 0.228, 0.248, 0.392]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ig_values =[]\n",
    "for i in range(len(data_transpose)-1):\n",
    "    ig_values.append(ig(data_transpose,data_transpose[i]))\n",
    "    \n",
    "ig_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.42)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from math import log\n",
    "\n",
    "def IG(file_path, sampletxt, att_no):\n",
    "\n",
    "    def entropy_root(data):\n",
    "        (unique, counts) = np.unique(data, return_counts=True)\n",
    "        n = len(data)\n",
    "        ent =0\n",
    "        for i in counts:\n",
    "            p = i/n\n",
    "            ent+= -(p*log(p,2))\n",
    "\n",
    "        return ent\n",
    "\n",
    "    def entropy(attr, clas):\n",
    "        ent = 0\n",
    "        uniq = np.unique(attr)\n",
    "        uniq_class = np.unique(clas)\n",
    "    #     print(uniq_class)\n",
    "        for i in uniq:\n",
    "            temp_ent = 0\n",
    "            temp = np.zeros(len(uniq_class))\n",
    "    #         print(temp)\n",
    "            indices = np.where(attr == i)\n",
    "    #         print(indices[0])\n",
    "            n = len(indices[0])\n",
    "    #         print(n/len(data))\n",
    "    #         print(z)\n",
    "            for j in indices[0]:\n",
    "    #             print(j)\n",
    "                for k in range(len(uniq_class)):\n",
    "                    if clas[j] == uniq_class[k]:\n",
    "                        temp[k] += 1\n",
    "            temp_p = temp/n\n",
    "    #         print(temp_p)\n",
    "    #         print(z)\n",
    "            for i in temp_p:\n",
    "                if i != 0:\n",
    "                    temp_ent += -(i*log(i,2))\n",
    "    #         print(temp_ent)  \n",
    "    #         print(z)\n",
    "            ent += temp_ent*(n/len(data))\n",
    "\n",
    "        return round(ent,3)\n",
    "    \n",
    "\n",
    "    def ig(data, attr):\n",
    "        return round(entropy_root(data_transpose[-1]) - entropy(attr, data_transpose[-1]),3)\n",
    "    \n",
    "\n",
    "    temp = np.loadtxt(fname = os.path.join(file_path, sampletxt), delimiter= '\\n', dtype= str)\n",
    "    data_temp = [i.replace('{','').replace('}', '').split(',') for i in temp]\n",
    "    data = np.asarray([[i for i in j] for j in data_temp])\n",
    "\n",
    "    data_transpose = np.transpose(data)\n",
    "\n",
    "#     uniq_attr = [np.unique(i) for i in data_transpose]\n",
    "#     root_ent = entropy_root(data_transpose[-1]) \n",
    "\n",
    "    attr = data_transpose[att_no]\n",
    "    value  = ig(data, attr)\n",
    "    print('(' + str(value) + ')')\n",
    "    \n",
    "    \n",
    "file_path = r'C:\\Users\\kalya\\OneDrive - University of Illinois at Chicago\\!UIC\\!Semesters\\3rd Sem\\CS 583 Data Mining and Text Mining\\Assignements\\Assignment 2'\n",
    "IG(file_path, 'Sample3.txt', 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
